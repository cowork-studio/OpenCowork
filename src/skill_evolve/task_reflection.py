#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Copyright (c) 2025 OfficeCowork Research Group.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

"""
ä»»åŠ¡åæ€è„šæœ¬
åˆ†æä»»åŠ¡æ—¥å¿—ï¼Œä½¿ç”¨LLMè¿›è¡Œæ·±åº¦åæ€ï¼Œç”Ÿæˆskillæ–‡ä»¶
"""

import os
import re
import argparse
import logging
import yaml
import time
import requests
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

from src.config_loader import (
    load_config, get_api_key, get_api_base, get_model,
    get_gui_default_data_directory
)
from src.tools.print_system import print_current, print_error, print_system
from .skill_tools import SkillTools


class TaskReflection:
    """ä»»åŠ¡åæ€å¤„ç†å™¨"""
    
    def __init__(self, root_dir: Optional[str] = None, config_file: str = "config/config.txt"):
        """
        åˆå§‹åŒ–ä»»åŠ¡åæ€å¤„ç†å™¨
        
        Args:
            root_dir: æ ¹ç›®å½•ï¼ˆå¦‚æœæŒ‡å®šï¼Œè¦†ç›–configä¸­çš„è®¾ç½®ï¼‰
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_file = config_file
        self.config = load_config(config_file)
        
        # ç¡®å®šæ ¹ç›®å½•
        if root_dir:
            self.root_dir = os.path.abspath(root_dir)
        else:
            data_dir = get_gui_default_data_directory(config_file)
            if data_dir:
                self.root_dir = data_dir
            else:
                # é»˜è®¤ä½¿ç”¨dataç›®å½•
                project_root = self._find_project_root()
                self.root_dir = os.path.join(project_root, "data") if project_root else "data"
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self.api_key = get_api_key(config_file)
        self.api_base = get_api_base(config_file)
        self.model = get_model(config_file)
        
        self.llm_client = None
        self.is_claude = False
        
        if self.api_key and self.model:
            if 'claude' in self.model.lower() or 'anthropic' in str(self.api_base).lower():
                if ANTHROPIC_AVAILABLE:
                    # å¯¹äºminimaxå’ŒGLMç­‰ä½¿ç”¨Anthropicå…¼å®¹APIçš„æœåŠ¡ï¼Œéœ€è¦ä¼ å…¥base_url
                    if 'bigmodel.cn' in str(self.api_base).lower() or 'minimaxi.com' in str(self.api_base).lower():
                        self.llm_client = anthropic.Anthropic(api_key=self.api_key, base_url=self.api_base)
                    else:
                        self.llm_client = anthropic.Anthropic(api_key=self.api_key)
                    self.is_claude = True
            else:
                if OPENAI_AVAILABLE:
                    self.llm_client = OpenAI(api_key=self.api_key, base_url=self.api_base)
        
        # åˆå§‹åŒ–skillå·¥å…·
        self.skill_tools = SkillTools(workspace_root=self.root_dir)
        
        # è®¾ç½®æ—¥å¿—
        self.logger = self._setup_logger()
    
    def _find_project_root(self) -> Optional[str]:
        """æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•"""
        current = Path(__file__).resolve()
        for _ in range(10):
            config_dir = current / "config"
            if config_dir.exists() and config_dir.is_dir():
                return str(current)
            if current == current.parent:
                break
            current = current.parent
        return None
    
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('task_reflection')
        logger.setLevel(logging.INFO)
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        if self.skill_tools.experience_dir:
            log_dir = os.path.join(self.skill_tools.experience_dir, "logs")
            os.makedirs(log_dir, exist_ok=True)
            
            # æ—¥å¿—æ–‡ä»¶
            log_file = os.path.join(log_dir, f"task_reflection_{datetime.now().strftime('%Y%m%d')}.log")
            
            # æ–‡ä»¶å¤„ç†å™¨
            file_handler = logging.FileHandler(log_file, encoding='utf-8')
            file_handler.setLevel(logging.INFO)
            
            # æ§åˆ¶å°å¤„ç†å™¨
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            
            # æ ¼å¼
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            file_handler.setFormatter(formatter)
            console_handler.setFormatter(formatter)
            
            logger.addHandler(file_handler)
            logger.addHandler(console_handler)
        
        return logger
    
    def _find_all_output_dirs(self) -> List[Tuple[str, float]]:
        """
        æŸ¥æ‰¾æ‰€æœ‰output_XXXç›®å½•
        
        æŸ¥æ‰¾èŒƒå›´ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
        1. data/output_XXX/ (ç›´æ¥åœ¨dataç›®å½•ä¸‹ï¼Œç”±cowork.pyç”Ÿæˆ)
        2. data/{user_dir}/output_XXX/ (æ ‡å‡†ç»“æ„)
        3. data/benchmark_results/*/baseline_outputs/output_XXX/ (è¯„æµ‹ç»“æ„)
        4. data/benchmark_results/*/skill_outputs/output_XXX/ (è¯„æµ‹ç»“æ„)
        
        Returns:
            [(ç›®å½•è·¯å¾„, ä¿®æ”¹æ—¶é—´), ...] åˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´å€’åº
        """
        output_dirs = []
        
        if not os.path.exists(self.root_dir):
            self.logger.warning(f"Root directory not found: {self.root_dir}")
            return output_dirs
        
        # æ–¹æ³•0: ç›´æ¥åœ¨dataç›®å½•ä¸‹æŸ¥æ‰¾ output_XXXï¼ˆç”±cowork.pyç”Ÿæˆçš„ç»“æ„ï¼‰
        for item in os.listdir(self.root_dir):
            item_path = os.path.join(self.root_dir, item)
            if os.path.isdir(item_path) and item.startswith('output_'):
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„outputç›®å½•ï¼ˆåŒ…å«workspaceæˆ–logsç›®å½•ï¼‰
                workspace_dir = os.path.join(item_path, "workspace")
                logs_dir = os.path.join(item_path, "logs")
                if os.path.exists(workspace_dir) or os.path.exists(logs_dir):
                    try:
                        mtime = os.path.getmtime(item_path)
                        output_dirs.append((item_path, mtime))
                    except OSError:
                        continue
        
        # æ–¹æ³•1: éå†æ‰€æœ‰ç”¨æˆ·ç›®å½•ï¼ŒæŸ¥æ‰¾æ ‡å‡†ç»“æ„ data/{user_dir}/output_XXX/
        for item in os.listdir(self.root_dir):
            item_path = os.path.join(self.root_dir, item)
            if not os.path.isdir(item_path) or item.startswith('.') or item.startswith('output_'):
                continue
            
            # åœ¨ç”¨æˆ·ç›®å½•ä¸‹æŸ¥æ‰¾output_XXX
            try:
                for subitem in os.listdir(item_path):
                    subitem_path = os.path.join(item_path, subitem)
                    if os.path.isdir(subitem_path) and subitem.startswith('output_'):
                        mtime = os.path.getmtime(subitem_path)
                        output_dirs.append((subitem_path, mtime))
            except (OSError, PermissionError):
                continue
        
        # æ–¹æ³•2: æŸ¥æ‰¾è¯„æµ‹ç»“æ„ data/benchmark_results/*/baseline_outputs/output_XXX/
        benchmark_results_dir = os.path.join(self.root_dir, "benchmark_results")
        if os.path.exists(benchmark_results_dir):
            try:
                for benchmark_dir in os.listdir(benchmark_results_dir):
                    benchmark_path = os.path.join(benchmark_results_dir, benchmark_dir)
                    if not os.path.isdir(benchmark_path):
                        continue
                    
                    # æŸ¥æ‰¾ baseline_outputs å’Œ skill_outputs ç›®å½•
                    for output_type in ["baseline_outputs", "skill_outputs"]:
                        outputs_dir = os.path.join(benchmark_path, output_type)
                        if os.path.exists(outputs_dir):
                            try:
                                for output_item in os.listdir(outputs_dir):
                                    output_item_path = os.path.join(outputs_dir, output_item)
                                    if os.path.isdir(output_item_path) and output_item.startswith('output_'):
                                        mtime = os.path.getmtime(output_item_path)
                                        output_dirs.append((output_item_path, mtime))
                            except (OSError, PermissionError):
                                continue
            except (OSError, PermissionError):
                pass
        
        # å»é™¤é‡å¤ï¼ˆåŸºäºè·¯å¾„ï¼‰
        seen_paths = set()
        unique_output_dirs = []
        for output_dir, mtime in output_dirs:
            if output_dir not in seen_paths:
                seen_paths.add(output_dir)
                unique_output_dirs.append((output_dir, mtime))
        
        # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åº
        unique_output_dirs.sort(key=lambda x: x[1], reverse=True)
        return unique_output_dirs
    
    def _parse_log_file(self, log_file_path: str) -> Dict[str, Any]:
        """
        è§£ææ—¥å¿—æ–‡ä»¶
        
        Args:
            log_file_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            
        Returns:
            è§£æç»“æœå­—å…¸
        """
        result = {
            'user_requirements': [],
            'tool_calls': [],
            'errors': [],
            'task_completed': False,
            'user_interruptions': [],
            'agent_messages': [],
            'log_content': ''  # ä¿å­˜å®Œæ•´æ—¥å¿—å†…å®¹
        }
        
        if not os.path.exists(log_file_path):
            return result
        
        try:
            with open(log_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # ä¿å­˜æ—¥å¿—å†…å®¹ï¼ˆå¦‚æœå¤ªé•¿åˆ™æˆªå–å…³é”®éƒ¨åˆ†ï¼‰
            # æé«˜é˜ˆå€¼åˆ°50000ï¼Œç¡®ä¿èƒ½åŒ…å«æ›´å¤šä¸Šä¸‹æ–‡
            if len(content) > 50000:
                # å¦‚æœæ—¥å¿—å¤ªé•¿ï¼Œä¿ç•™å¼€å¤´ã€å¤±è´¥ç‚¹å’ŒæˆåŠŸç‚¹é™„è¿‘çš„å†…å®¹
                lines = content.split('\n')
                # ä¿ç•™å‰2000è¡Œï¼ˆå¢åŠ å¼€å¤´ä¿ç•™é‡ï¼‰
                start_lines = lines[:2000]
                
                # æŸ¥æ‰¾å…³é”®ä¿¡æ¯ä½ç½®
                # 1. æ¸¸æˆç±»å‹å’Œè§„åˆ™ç›¸å…³çš„è¡Œï¼ˆæ£‹ç›˜å¤§å°ã€æ¸¸æˆè§„åˆ™ç­‰ï¼‰
                game_info_indices = []
                for i, line in enumerate(lines):
                    if any(keyword in line for keyword in ['12x12', 'æ£‹ç›˜', 'äº”å­æ£‹', 'Gomoku', 'è¿æˆ', 'è·èƒœ', 'è§„åˆ™', 'game']):
                        game_info_indices.append(i)
                
                # 2. å¤±è´¥ç‚¹
                failure_indices = [i for i, line in enumerate(lines) if 'æ¸¸æˆç»“æŸ' in line and 'ç¯å¢ƒè·èƒœ' in line or 'âŒ' in line]
                
                # 3. æˆåŠŸç‚¹
                success_indices = [i for i, line in enumerate(lines) if ('è·èƒœ' in line and 'å¤§æ¨¡å‹è·èƒœ' in line) or 'ğŸ‰' in line or 'TASK_COMPLETED' in line]
                
                # æ”¶é›†å…³é”®åŒºåŸŸ
                key_lines = []
                seen_indices = set()
                
                # æ”¶é›†æ¸¸æˆä¿¡æ¯ç›¸å…³è¡Œï¼ˆå‰åå„50è¡Œï¼‰
                for idx in game_info_indices[:5]:  # å‰5ä¸ªæ¸¸æˆä¿¡æ¯ç‚¹
                    for i in range(max(0, idx-50), min(len(lines), idx+50)):
                        if i not in seen_indices:
                            key_lines.append(lines[i])
                            seen_indices.add(i)
                
                # æ”¶é›†å¤±è´¥ç‚¹å‰åå„150è¡Œï¼ˆå¢åŠ ä¸Šä¸‹æ–‡ï¼‰
                for idx in failure_indices[:5]:  # æœ€å¤š5ä¸ªå¤±è´¥ç‚¹
                    for i in range(max(0, idx-150), min(len(lines), idx+150)):
                        if i not in seen_indices:
                            key_lines.append(lines[i])
                            seen_indices.add(i)
                
                # æ”¶é›†æˆåŠŸç‚¹å‰åå„200è¡Œï¼ˆå®Œæ•´ä¿ç•™æˆåŠŸè¿‡ç¨‹ï¼‰
                for idx in success_indices:
                    for i in range(max(0, idx-200), min(len(lines), idx+200)):
                        if i not in seen_indices:
                            key_lines.append(lines[i])
                            seen_indices.add(i)
                
                # æŒ‰è¡Œå·æ’åºï¼Œä¿æŒæ—¶é—´é¡ºåº
                key_lines_with_idx = [(i, lines[i]) for i in seen_indices if i >= 2000]  # æ’é™¤å·²åŒ…å«åœ¨start_linesä¸­çš„è¡Œ
                key_lines_with_idx.sort()
                key_lines_ordered = [line for _, line in key_lines_with_idx]
                
                # åˆå¹¶å†…å®¹
                result['log_content'] = '\n'.join(start_lines) + '\n... [ä¸­é—´éƒ¨åˆ†å·²çœç•¥ï¼Œä»…ä¿ç•™å…³é”®ä¿¡æ¯] ...\n' + '\n'.join(key_lines_ordered)
                self.logger.info(f"Log content truncated from {len(content)} to {len(result['log_content'])} characters")
            else:
                result['log_content'] = content
                self.logger.info(f"Log content preserved in full: {len(content)} characters")
            
            # æå–ç”¨æˆ·éœ€æ±‚
            user_req_pattern = r'Received user requirement[:\s]+(.+?)(?:\n|$)'
            for match in re.finditer(user_req_pattern, content, re.MULTILINE | re.IGNORECASE):
                result['user_requirements'].append(match.group(1).strip())
            
            # æå–å·¥å…·è°ƒç”¨ï¼ˆXMLæ ¼å¼ï¼‰
            tool_call_pattern = r'<invoke[^>]*>(.*?)</invoke>'
            for match in re.finditer(tool_call_pattern, content, re.DOTALL):
                result['tool_calls'].append(match.group(0))
            
            # æå–é”™è¯¯åé¦ˆ
            error_pattern = r'ERROR FEEDBACK[:\s]+(.+?)(?:\n|$)'
            for match in re.finditer(error_pattern, content, re.MULTILINE | re.IGNORECASE):
                result['errors'].append(match.group(1).strip())
            
            # æ£€æŸ¥TASK_COMPLETED
            if 'TASK_COMPLETED' in content or 'TASK COMPLETED' in content:
                result['task_completed'] = True
            
            # æ£€æµ‹ç”¨æˆ·ä¸­æ–­ç‚¹
            # user requirementä¹‹å‰200ä¸ªå­—ç¬¦å†…æ²¡æœ‰TASK_COMPLETEDï¼ˆç¬¬ä¸€è¡Œé™¤å¤–ï¼‰
            lines = content.split('\n')
            for i, line in enumerate(lines):
                if 'Received user requirement' in line or 'user requirement' in line.lower():
                    if i == 0:
                        continue
                    
                    # æ£€æŸ¥å‰200ä¸ªå­—ç¬¦
                    prev_text = '\n'.join(lines[max(0, i-10):i])
                    if len(prev_text) > 200:
                        prev_text = prev_text[-200:]
                    
                    if 'TASK_COMPLETED' not in prev_text and 'TASK COMPLETED' not in prev_text:
                        result['user_interruptions'].append({
                            'line': i,
                            'requirement': line.strip()
                        })
            
            # æå–agentæ¶ˆæ¯ï¼ˆå¦‚æœæ˜¯agentæ—¥å¿—ï¼‰
            if 'agent_' in os.path.basename(log_file_path):
                agent_msg_pattern = r'Agent\s+\d+.*?:(.+?)(?:\n|$)'
                for match in re.finditer(agent_msg_pattern, content, re.MULTILINE | re.IGNORECASE):
                    result['agent_messages'].append(match.group(1).strip())
        
        except Exception as e:
            self.logger.error(f"Error parsing log file {log_file_path}: {e}")
        
        return result
    
    def _call_llm_reflection(self, task_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        è°ƒç”¨LLMè¿›è¡Œæ·±åº¦åæ€
        
        Args:
            task_info: ä»»åŠ¡ä¿¡æ¯å­—å…¸
            
        Returns:
            LLMåæ€ç»“æœï¼ŒåŒ…å«åæ€å†…å®¹å’Œéœ€è¦å¤‡ä»½çš„æ–‡ä»¶åˆ—è¡¨
        """
        if not self.llm_client:
            return {
                'reflection': 'LLM client not available',
                'files_to_backup': []
            }
        
        # æ„å»ºåæ€æç¤º
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªç»éªŒæ€»ç»“ä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹ä»»åŠ¡æ‰§è¡Œå†å²è¿›è¡Œæ·±åº¦åæ€å’Œåˆ†æã€‚

**é‡è¦è¦æ±‚ï¼š**
1. **å¿…é¡»ä½¿ç”¨ä¸­æ–‡è¾“å‡º**ï¼Œä¸è¦ä½¿ç”¨è‹±æ–‡æˆ–å…¶ä»–è¯­è¨€
2. è¾“å‡ºå†…å®¹å¿…é¡»ç®€æ´å‡ç»ƒï¼Œé¿å…é‡å¤ã€‚æ¯ä¸ªè¦ç‚¹åªå†™ä¸€æ¬¡ï¼Œä¸è¦é‡å¤æè¿°ç›¸åŒçš„å¤±è´¥æˆ–æˆåŠŸè¿‡ç¨‹
3. ä¸è¦åŒ…å«æ€è€ƒè¿‡ç¨‹æˆ–è¿‡æ¸¡è¯­å¥ï¼ˆå¦‚"Let me analyze..."ã€"Let me structure..."ç­‰ï¼‰
4. ç›´æ¥æŒ‰ç…§è¦æ±‚çš„æ ¼å¼è¾“å‡ºå†…å®¹ï¼Œä¸è¦å…ˆå†™ä¸€ä¸ªç‰ˆæœ¬å†å†™å¦ä¸€ä¸ªç‰ˆæœ¬

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼ˆæ¯ä¸ªè§’åº¦ç®€æ´æ¦‚æ‹¬ï¼Œé¿å…å†—é•¿é‡å¤ï¼‰ï¼š
1. ä»»åŠ¡å®Œæˆæƒ…å†µï¼šæ˜¯å¦æˆåŠŸå®Œæˆï¼Œç”¨æˆ·æ˜¯å¦æ»¡æ„ï¼ˆä¸€å¥è¯æ¦‚æ‹¬ï¼‰
2. ç”¨æˆ·ä¸­æ–­åˆ†æï¼šå¦‚æœ‰ç”¨æˆ·ä¸­æ–­ï¼Œç®€è¦åˆ†æåŸå› å’Œç”¨æˆ·åå¥½
3. æ ¸å¿ƒç»éªŒæ€»ç»“ï¼ˆæœ€é‡è¦ï¼‰ï¼š
   - å¦‚æœä»»åŠ¡æ¶‰åŠæ¸¸æˆï¼Œå¿…é¡»ç®€æ´æ€»ç»“ï¼šæ¸¸æˆç±»å‹ã€è¾“èµ¢è§„åˆ™
   - å¦‚æœä»»åŠ¡å¤šæ¬¡å¤±è´¥åæˆåŠŸï¼Œç®€è¦è¯´æ˜ï¼šå¤±è´¥çš„ä¸»è¦åŸå› ï¼ˆå…³é”®ç‚¹ï¼‰å’Œæœ€ç»ˆæˆåŠŸçš„ç­–ç•¥ï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰
4. æœ€çŸ­æˆåŠŸè·¯å¾„ï¼šéœ€æè¿°æ¸…æ¥šï¼Œæˆ–è¯´æ˜ä¸å­˜åœ¨æ˜æ˜¾ä¼˜åŒ–ç©ºé—´
5. ç”¨æˆ·åå¥½ï¼šç®€è¦æ€»ç»“
6. Skillä½¿ç”¨æ¡ä»¶ï¼šæ¸…æ™°æè¿°ä½•æ—¶ä»¥åŠä»€ä¹ˆæƒ…å†µä¸‹åº”è¯¥ä½¿ç”¨è¿™ä¸ªskillï¼ˆä¾‹å¦‚ï¼š"å½“ç”¨æˆ·æƒ³è¦ä½¿ç”¨è‡ªå®šä¹‰å·¥å…·ç©ç±»ä¼¼äº”å­æ£‹çš„æ¸¸æˆå¹¶å°è¯•è·èƒœæ—¶"ã€"å½“å¤„ç†éœ€è¦å¤šæ¬¡è¿­ä»£æ‰èƒ½æˆåŠŸçš„ä»»åŠ¡æ—¶"ç­‰ï¼Œè¦å…·ä½“æ˜ç¡®ï¼‰
7. éœ€è¦å¤‡ä»½çš„æ–‡ä»¶ï¼šåˆ—å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆåªåŒ…æ‹¬ä»£ç æ–‡ä»¶å¦‚.pyã€.jsã€.tsã€.javaç­‰å’Œæ–‡æ¡£æ–‡ä»¶å¦‚.mdã€.txtç­‰ï¼Œä¸åŒ…æ‹¬é…ç½®æ–‡ä»¶å¦‚.jsonã€.yamlç­‰å’Œå›¾ç‰‡æ–‡ä»¶ï¼‰

**è¦æ±‚ï¼š**
- æ€»é•¿åº¦æ§åˆ¶åœ¨800-1500å­—
- ç»“æ„æ¸…æ™°ï¼Œæ¯ä¸ªéƒ¨åˆ†2-4å¥è¯æ¦‚æ‹¬
- å¤±è´¥å’ŒæˆåŠŸçš„è¿­ä»£è¿‡ç¨‹åªæè¿°ä¸€æ¬¡ï¼Œè¦ç®€æ´
- é‡ç‚¹çªå‡ºæ ¸å¿ƒæ´å¯Ÿå’Œç»éªŒæ•™è®­
- ä¸è¦é‡å¤åˆ—ä¸¾æ¯æ¬¡å¤±è´¥
- Skillä½¿ç”¨æ¡ä»¶è¦å…·ä½“æ˜ç¡®ï¼Œèƒ½å¤Ÿå¸®åŠ©ç³»ç»Ÿå‡†ç¡®åˆ¤æ–­ä½•æ—¶åº”è¯¥ä½¿ç”¨è¿™ä¸ªskill

**è¾“å‡ºæ ¼å¼ï¼š**
- ä½¿ç”¨ä¸­æ–‡è‡ªç„¶è¯­è¨€æ ¼å¼
- ç›´æ¥æŒ‰ç…§ä¸Šè¿°7ä¸ªè§’åº¦é€ä¸€åˆ†æï¼Œä¸è¦é‡å¤
- ä¸è¦åŒ…å«æ ‡é¢˜"ä»»åŠ¡æ‰§è¡Œåæ€åˆ†æ"æˆ–ç±»ä¼¼çš„ç»“æ„åŒ–æ ‡é¢˜ï¼ˆå¦‚"## Task Overview"ç­‰ï¼‰
- åœ¨æœ€åå•ç‹¬åˆ—å‡ºï¼š
  1. éœ€è¦å¤‡ä»½çš„æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œä»¥"FILES_TO_BACKUP:"å¼€å¤´ï¼‰
  2. Skillä½¿ç”¨æ¡ä»¶ï¼ˆå•ç‹¬ä¸€è¡Œï¼Œä»¥"USAGE_CONDITIONS:"å¼€å¤´ï¼‰

è¯·ç›´æ¥å¼€å§‹åˆ†æï¼Œä½¿ç”¨ä¸­æ–‡è¾“å‡ºã€‚"""

        # è·å–manager.outçš„è¯¦ç»†å†…å®¹
        manager_log_content = task_info.get('log_content', '')
        
        # è®°å½•æ—¥å¿—å†…å®¹é•¿åº¦ï¼Œç”¨äºè°ƒè¯•
        self.logger.info(f"Manager.out content length: {len(manager_log_content)} characters")
        
        # å¦‚æœå†…å®¹ä¸ºç©ºï¼Œè®°å½•è­¦å‘Š
        if not manager_log_content:
            self.logger.warning("Manager.out content is empty! LLM will not see detailed execution history.")
        
        user_prompt = f"""ä»»åŠ¡ç›®å½•: {task_info['output_dir']}
ç”¨æˆ·éœ€æ±‚: {task_info.get('user_requirements', [])}
å·¥å…·è°ƒç”¨æ¬¡æ•°: {len(task_info.get('tool_calls', []))}
é”™è¯¯æ¬¡æ•°: {len(task_info.get('errors', []))}
ä»»åŠ¡å®Œæˆ: {'æ˜¯' if task_info.get('task_completed') else 'å¦'}
ç”¨æˆ·ä¸­æ–­æ¬¡æ•°: {len(task_info.get('user_interruptions', []))}

æ—¥å¿—æ‘˜è¦:
{task_info.get('log_summary', '')}

è¯¦ç»†æ‰§è¡Œå†å²ï¼ˆmanager.outå†…å®¹ï¼‰:
{manager_log_content if manager_log_content else 'æ—¥å¿—å†…å®¹ä¸ºç©º'}

è¯·ä»”ç»†é˜…è¯»ä¸Šè¿°è¯¦ç»†æ‰§è¡Œå†å²ï¼Œè¿›è¡Œç®€æ´å‡ç»ƒçš„æ€»ç»“åˆ†æã€‚æ³¨æ„ï¼š
- æ¯ä¸ªè¦ç‚¹åªå†™ä¸€æ¬¡ï¼Œé¿å…é‡å¤
- å†…å®¹è¦ç®€æ´ï¼Œçªå‡ºæ ¸å¿ƒæ´å¯Ÿ
- å¦‚æœæ¶‰åŠæ¸¸æˆï¼Œæå–æ¸¸æˆç±»å‹å’Œè§„åˆ™
- å¦‚æœå¤šæ¬¡å¤±è´¥åæˆåŠŸï¼Œç®€è¦è¯´æ˜å¤±è´¥åŸå› å’ŒæˆåŠŸç­–ç•¥ï¼ˆä¸è¦é‡å¤åˆ—ä¸¾æ¯æ¬¡å¤±è´¥ï¼‰
- **é‡è¦ï¼šè¯·æ€»ç»“skillçš„ä½¿ç”¨æ¡ä»¶ï¼Œæè¿°åœ¨ä»€ä¹ˆæƒ…å†µä¸‹åº”è¯¥ä½¿ç”¨è¿™ä¸ªskillï¼ˆè¦å…·ä½“æ˜ç¡®ï¼Œèƒ½å¤Ÿå¸®åŠ©ç³»ç»Ÿå‡†ç¡®åˆ¤æ–­ï¼‰**

è¯·è¿›è¡Œç®€æ´çš„æ·±åº¦åæ€åˆ†æã€‚"""
        
        # è®°å½•å®é™…ä¼ é€’ç»™LLMçš„prompté•¿åº¦
        self.logger.info(f"User prompt length: {len(user_prompt)} characters")
        
        try:
            if self.is_claude:
                # ä½¿ç”¨Anthropicå®¢æˆ·ç«¯ï¼ˆæ”¯æŒæ ‡å‡†Anthropic APIå’Œå…¼å®¹APIå¦‚minimaxã€GLMï¼‰
                response = self.llm_client.messages.create(
                    model=self.model,
                    max_tokens=4000,
                    system=system_prompt,
                    messages=[{"role": "user", "content": user_prompt}],
                    temperature=0.7
                )
                # æ­£ç¡®å¤„ç†ä¸åŒç±»å‹çš„content blockï¼ˆtextå’Œthinkingï¼‰
                reflection_text = ""
                for content_block in response.content:
                    if hasattr(content_block, 'type'):
                        if content_block.type == "text":
                            reflection_text += getattr(content_block, 'text', '')
                        elif content_block.type == "thinking":
                            # thinking blockå¯èƒ½æœ‰textæˆ–thinkingå±æ€§
                            thinking_text = getattr(content_block, 'text', None) or getattr(content_block, 'thinking', None)
                            if thinking_text:
                                reflection_text += thinking_text
                    else:
                        # å…¼å®¹æ—§ç‰ˆæœ¬ï¼Œç›´æ¥å°è¯•textå±æ€§
                        reflection_text += getattr(content_block, 'text', '')
            else:
                response = self.llm_client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    max_tokens=4000,
                    temperature=0.7
                )
                reflection_text = response.choices[0].message.content if response.choices else ""
            
            # è§£ææ–‡ä»¶åˆ—è¡¨å’Œä½¿ç”¨æ¡ä»¶
            files_to_backup = []
            usage_conditions = None
            
            # æå–FILES_TO_BACKUPï¼ˆåº”è¯¥åœ¨USAGE_CONDITIONSä¹‹å‰ï¼‰
            if 'FILES_TO_BACKUP:' in reflection_text:
                files_section = reflection_text.split('FILES_TO_BACKUP:')[1].strip()
                # å¦‚æœUSAGE_CONDITIONSåœ¨FILES_TO_BACKUPä¹‹åï¼Œéœ€è¦æ’é™¤å®ƒ
                if 'USAGE_CONDITIONS:' in files_section:
                    files_section = files_section.split('USAGE_CONDITIONS:')[0].strip()
                for line in files_section.split('\n'):
                    line = line.strip()
                    if line and not line.startswith('#') and not line.startswith('USAGE_CONDITIONS:'):
                        files_to_backup.append(line)
            
            # æå–USAGE_CONDITIONS
            if 'USAGE_CONDITIONS:' in reflection_text:
                usage_section = reflection_text.split('USAGE_CONDITIONS:')[1].strip()
                # æå–ç¬¬ä¸€è¡Œä½œä¸ºusage conditionsï¼ˆå»é™¤å¯èƒ½çš„é¢å¤–å†…å®¹ï¼‰
                usage_conditions = usage_section.split('\n')[0].strip()
                # å¦‚æœè¿˜æœ‰FILES_TO_BACKUPåœ¨åé¢ï¼Œéœ€è¦æ’é™¤
                if 'FILES_TO_BACKUP:' in usage_conditions:
                    usage_conditions = usage_conditions.split('FILES_TO_BACKUP:')[0].strip()
            
            # ç§»é™¤æ–‡ä»¶åˆ—è¡¨å’Œä½¿ç”¨æ¡ä»¶éƒ¨åˆ†ï¼Œè·å–çº¯åæ€å†…å®¹
            reflection = reflection_text
            if 'FILES_TO_BACKUP:' in reflection:
                reflection = reflection.split('FILES_TO_BACKUP:')[0].strip()
            if 'USAGE_CONDITIONS:' in reflection:
                reflection = reflection.split('USAGE_CONDITIONS:')[0].strip()
            
            return {
                'reflection': reflection,
                'files_to_backup': files_to_backup,
                'usage_conditions': usage_conditions
            }
        
        except Exception as e:
            self.logger.error(f"Error calling LLM: {e}")
            return {
                'reflection': f'Error in LLM call: {str(e)}',
                'files_to_backup': [],
                'usage_conditions': None
            }
    
    def _backup_files(self, output_dir: str, files_to_backup: List[str], skill_id: str) -> List[str]:
        """
        å¤‡ä»½æ–‡ä»¶åˆ°skillä»£ç ç›®å½•
        
        Args:
            output_dir: ä»»åŠ¡è¾“å‡ºç›®å½•
            files_to_backup: è¦å¤‡ä»½çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆç›¸å¯¹äºworkspaceï¼‰
            skill_id: skill ID
            
        Returns:
            æˆåŠŸå¤‡ä»½çš„æ–‡ä»¶åˆ—è¡¨
        """
        workspace_dir = os.path.join(output_dir, "workspace")
        if not os.path.exists(workspace_dir):
            return []
        
        copied_files = []
        
        for file_path in files_to_backup:
            try:
                # æ„å»ºå®Œæ•´è·¯å¾„
                if os.path.isabs(file_path):
                    src_path = file_path
                else:
                    src_path = os.path.join(workspace_dir, file_path)
                
                if not os.path.exists(src_path):
                    continue
                
                # åªå¤‡ä»½ä»£ç æ–‡ä»¶å’Œæ–‡æ¡£æ–‡ä»¶
                ext = os.path.splitext(src_path)[1].lower()
                code_exts = {'.py', '.js', '.ts', '.java', '.cpp', '.c', '.h', '.hpp', '.go', '.rs', '.rb', '.php'}
                doc_exts = {'.md', '.txt', '.rst'}
                
                if ext not in code_exts and ext not in doc_exts:
                    continue
                
                # ä½¿ç”¨copy_skill_fileså·¥å…·å¤‡ä»½
                rel_path = os.path.relpath(src_path, workspace_dir)
                result = self.skill_tools.copy_skill_files(skill_id, [rel_path])
                if result.get('status') == 'success':
                    copied_files.extend(result.get('copied_files', []))
            
            except Exception as e:
                self.logger.error(f"Error backing up file {file_path}: {e}")
        
        return copied_files
    
    def _generate_skill(self, task_info: Dict[str, Any], reflection_result: Dict[str, Any]) -> Optional[str]:
        """
        ç”Ÿæˆskillæ–‡ä»¶
        
        Args:
            task_info: ä»»åŠ¡ä¿¡æ¯
            reflection_result: åæ€ç»“æœ
            
        Returns:
            ç”Ÿæˆçš„skillæ–‡ä»¶è·¯å¾„
        """
        if not self.skill_tools.experience_dir:
            return None
        
        try:
            # ç”Ÿæˆskill_idï¼ˆä½¿ç”¨æ—¶é—´æˆ³ï¼‰
            skill_id = str(int(time.time()))
            
            # ä»åæ€å†…å®¹ä¸­æå–æ ‡é¢˜ï¼ˆä½¿ç”¨ç¬¬ä¸€è¡Œæˆ–å‰50ä¸ªå­—ç¬¦ï¼‰
            reflection = reflection_result.get('reflection', '')
            title = reflection.split('\n')[0][:50] if reflection else f"Task from {task_info['output_dir']}"
            if not title:
                title = f"Task from {os.path.basename(task_info['output_dir'])}"
            
            # ç”Ÿæˆæ–‡ä»¶å
            safe_title = self.skill_tools._sanitize_filename(title)
            skill_filename = f"skill_{safe_title}.md"
            skill_file_path = os.path.join(self.skill_tools.experience_dir, skill_filename)
            
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³
            if os.path.exists(skill_file_path):
                name, ext = os.path.splitext(skill_filename)
                skill_filename = f"{name}_{skill_id}{ext}"
                skill_file_path = os.path.join(self.skill_tools.experience_dir, skill_filename)
            
            # æ„å»ºfront matter
            user_requirements = task_info.get('user_requirements', [])
            # ä¼˜å…ˆä½¿ç”¨LLMç”Ÿæˆçš„usage_conditionsï¼Œå¦åˆ™ä½¿ç”¨user_requirements
            usage_conditions_from_llm = reflection_result.get('usage_conditions')
            if usage_conditions_from_llm:
                usage_conditions_text = usage_conditions_from_llm
            else:
                usage_conditions_text = user_requirements[0][:100] if user_requirements and user_requirements[0] else "é€šç”¨ä»»åŠ¡"
                # å¦‚æœä½¿ç”¨user_requirementsï¼ŒåŠ ä¸Šå‰ç¼€
                if usage_conditions_text and not usage_conditions_text.startswith("å½“"):
                    usage_conditions_text = f"å½“éœ€è¦å®Œæˆç±»ä¼¼ä»»åŠ¡æ—¶ä½¿ç”¨ï¼š{usage_conditions_text}"
            
            front_matter = {
                'skill_id': skill_id,
                'title': title,
                'usage_conditions': usage_conditions_text,
                'quality_index': 0.5,
                'fetch_count': 0,
                'related_code': '',
                'task_directories': [os.path.basename(task_info['output_dir'])],
                'created_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat(),
                'last_used_at': None,
                'user_preferences': ''
            }
            
            # æå–ç”¨æˆ·åå¥½ï¼ˆä»åæ€å†…å®¹ä¸­ï¼‰
            if 'ç”¨æˆ·åå¥½' in reflection or 'user preference' in reflection.lower():
                # ç®€å•æå–ï¼Œå¯ä»¥åç»­æ”¹è¿›
                front_matter['user_preferences'] = "ä»åæ€ä¸­æå–çš„ç”¨æˆ·åå¥½ä¿¡æ¯"
            
            # ä¿å­˜skillæ–‡ä»¶
            self.skill_tools._save_skill_file(skill_file_path, front_matter, reflection)
            
            # å¤‡ä»½æ–‡ä»¶
            files_to_backup = reflection_result.get('files_to_backup', [])
            if files_to_backup:
                copied_files = self._backup_files(task_info['output_dir'], files_to_backup, skill_id)
                if copied_files:
                    # æ›´æ–°related_code
                    front_matter['related_code'] = ', '.join(copied_files)
                    self.skill_tools._save_skill_file(skill_file_path, front_matter, reflection)
            
            return skill_file_path
        
        except Exception as e:
            self.logger.error(f"Error generating skill: {e}")
            return None
    
    def process_task(self, output_dir: str) -> bool:
        """
        å¤„ç†å•ä¸ªä»»åŠ¡
        
        Args:
            output_dir: ä»»åŠ¡è¾“å‡ºç›®å½•
            
        Returns:
            æ˜¯å¦æˆåŠŸå¤„ç†
        """
        try:
            self.logger.info(f"Processing task: {output_dir}")
            print_current(f"Processing: {output_dir}")
            
            # è§£ææ—¥å¿—æ–‡ä»¶
            logs_dir = os.path.join(output_dir, "logs")
            if not os.path.exists(logs_dir):
                self.logger.warning(f"Logs directory not found: {logs_dir}")
                return False
            
            # è§£æmanager.outï¼ˆä¿ç•™å®Œæ•´å†…å®¹ç”¨äºLLMåæ€ï¼‰
            manager_log = os.path.join(logs_dir, "manager.out")
            task_info = self._parse_log_file(manager_log)
            task_info['output_dir'] = output_dir
            
            # è§£æagentæ—¥å¿—
            for filename in os.listdir(logs_dir):
                if filename.startswith('agent_') and filename.endswith('.out'):
                    agent_log = os.path.join(logs_dir, filename)
                    agent_info = self._parse_log_file(agent_log)
                    task_info['agent_messages'].extend(agent_info.get('agent_messages', []))
                    # å¦‚æœagentæ—¥å¿—æœ‰å†…å®¹ï¼Œä¹Ÿåˆå¹¶åˆ°log_contentä¸­ï¼ˆä»…ä¿ç•™å…³é”®éƒ¨åˆ†ï¼‰
                    if agent_info.get('log_content') and len(agent_info.get('log_content', '')) < 5000:
                        if task_info.get('log_content'):
                            task_info['log_content'] += f"\n\n--- Agentæ—¥å¿— ({filename}) ---\n{agent_info['log_content']}"
                        else:
                            task_info['log_content'] = agent_info['log_content']
            
            # ç”Ÿæˆæ—¥å¿—æ‘˜è¦
            log_summary = f"""
å·¥å…·è°ƒç”¨: {len(task_info.get('tool_calls', []))}æ¬¡
é”™è¯¯: {len(task_info.get('errors', []))}ä¸ª
ç”¨æˆ·ä¸­æ–­: {len(task_info.get('user_interruptions', []))}æ¬¡
ä»»åŠ¡å®Œæˆ: {'æ˜¯' if task_info.get('task_completed') else 'å¦'}
"""
            task_info['log_summary'] = log_summary
            
            # LLMåæ€
            reflection_result = self._call_llm_reflection(task_info)
            
            # ç”Ÿæˆskillæ–‡ä»¶
            skill_file = self._generate_skill(task_info, reflection_result)
            
            if skill_file:
                self.logger.info(f"Skill file generated: {skill_file}")
                print_current(f"âœ… Skill generated: {skill_file}")
                return True
            else:
                self.logger.error("Failed to generate skill file")
                return False
        
        except Exception as e:
            self.logger.error(f"Error processing task {output_dir}: {e}", exc_info=True)
            return False
    
    def run(self):
        """è¿è¡Œä»»åŠ¡åæ€æµç¨‹"""
        self.logger.info(f"Starting task reflection process. Root directory: {self.root_dir}")
        print_system(f"Starting task reflection. Root directory: {self.root_dir}")
        
        # æŸ¥æ‰¾æ‰€æœ‰outputç›®å½•
        output_dirs = self._find_all_output_dirs()
        
        if not output_dirs:
            self.logger.warning("No output directories found")
            print_current("No output directories found")
            return
        
        self.logger.info(f"Found {len(output_dirs)} output directories")
        print_current(f"Found {len(output_dirs)} tasks to process")
        
        # å¤„ç†æ¯ä¸ªä»»åŠ¡
        success_count = 0
        for i, (output_dir, mtime) in enumerate(output_dirs, 1):
            print_current(f"[{i}/{len(output_dirs)}] Processing {os.path.basename(output_dir)}...")
            if self.process_task(output_dir):
                success_count += 1
        
        self.logger.info(f"Task reflection completed. Processed {success_count}/{len(output_dirs)} tasks successfully")
        print_system(f"âœ… Task reflection completed. Processed {success_count}/{len(output_dirs)} tasks successfully")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Task reflection script for skill generation')
    parser.add_argument('--root-dir', type=str, help='Root directory for data (overrides config)')
    parser.add_argument('--config', type=str, default='config/config.txt', help='Config file path')
    
    args = parser.parse_args()
    
    reflection = TaskReflection(root_dir=args.root_dir, config_file=args.config)
    reflection.run()


if __name__ == '__main__':
    main()



